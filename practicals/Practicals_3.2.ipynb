{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vigji/python-cimec-2025/blob/mila/practicals/Practicals_3.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#because we're in google colab, you need to install the required libraries each time you run the script. If running locally, you can create an environment with these libraries.\n",
        "!pip install openneuro-py pybids nibabel nilearn --quiet\n",
        "!pip install -q gdown\n",
        "!pip install bids --quiet"
      ],
      "metadata": {
        "id": "kBBcixZ47cqT"
      },
      "id": "kBBcixZ47cqT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9856b7cc-7c95-427c-81e2-9506f7d5fc52",
      "metadata": {
        "id": "9856b7cc-7c95-427c-81e2-9506f7d5fc52"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nibabel as nb\n",
        "import bids\n",
        "from openneuro import download\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17886266-8de0-498c-ba47-fc54677d7d61",
      "metadata": {
        "id": "17886266-8de0-498c-ba47-fc54677d7d61"
      },
      "source": [
        "# Practicals 3.3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc144cff-7ee9-4cd1-b16d-788e105490d7",
      "metadata": {
        "id": "dc144cff-7ee9-4cd1-b16d-788e105490d7"
      },
      "source": [
        "## Practicals 3.3.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access the files that I have uploaded on google drive\n",
        "!gdown 1RY_79IneZoH2X2pMO2TJ3EpGX2vC6ssR -O sub-001_task-rest_bold.nii.gz\n",
        "!gdown 1s-sr72U8w3apP0fAC_Jf5sfjPJG6w2y- -O sub-001_task-rest_boldmask.nii.gz\n",
        "!gdown 1Q10ezQSmKjAEnUy2WcmDescAobh2-LkT -O sub-001_T2w.nii.gz\n",
        "!gdown 1cDGvxdBm9XL844ZInM4CQXpImcKWB60f -O sub-001_task-rest_proc-cleaned_bold.nii.gz\n",
        "\n",
        "bold_img = nb.load(\"sub-001_task-rest_bold.nii.gz\") #load the file as nifti\n",
        "bold_mask = nb.load(\"sub-001_task-rest_boldmask.nii.gz\")\n",
        "anat_img = nb.load(\"sub-001_T2w.nii.gz\")\n",
        "bold_img_clean = nb.load(\"sub-001_task-rest_proc-cleaned_bold.nii.gz\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zwZPAHVxN11O"
      },
      "id": "zwZPAHVxN11O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what is the resolution of the BOLD and anat scans? (hint: print the header of the image and check the affine)\n",
        "# which one has the higher resolution?\n",
        "# do these two scans share the same origin/location within the MRI scanner?\n"
      ],
      "metadata": {
        "id": "TRZx4REFTlij"
      },
      "id": "TRZx4REFTlij",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the array of data from img\n",
        "\n",
        "\n",
        "# rescale the image so that all values are between 0 and 1\n",
        "\n",
        "\n",
        "# save the output as a nifti in the same folder as the original image, except indicate in the name that it has be rescaled\n"
      ],
      "metadata": {
        "id": "FWI5-tDV64mh"
      },
      "id": "FWI5-tDV64mh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3.2"
      ],
      "metadata": {
        "id": "adyPBPcen_kO"
      },
      "id": "adyPBPcen_kO"
    },
    {
      "cell_type": "code",
      "source": [
        "from nilearn import image as nli\n",
        "from nilearn import plotting\n",
        "\n",
        "# now load all 4 images with nilearn\n"
      ],
      "metadata": {
        "id": "Tsz2r7EYoHaC"
      },
      "id": "Tsz2r7EYoHaC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the anatomical image interactively and scroll through it (HINT THIS IS MOUSE DATA so set the bg_img to False otherwise you will see a human brain)\n",
        "\n"
      ],
      "metadata": {
        "id": "9ea9SKUbR_nO"
      },
      "id": "9ea9SKUbR_nO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# can you plot the bold scan interactively?\n"
      ],
      "metadata": {
        "id": "z-IqBAIbSLuj"
      },
      "id": "z-IqBAIbSLuj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3.3"
      ],
      "metadata": {
        "id": "sMjoa5Neo5IH"
      },
      "id": "sMjoa5Neo5IH"
    },
    {
      "cell_type": "code",
      "source": [
        "from nilearn.masking import apply_mask\n",
        "\n",
        "# drop the first 10 timepoints from the bold scan\n",
        "\n",
        "# apply the mask to the resulting bold scan\n",
        "\n",
        "\n",
        "\n",
        "# how many voxels are inside the brain and how many are outside the brain? (hint: compare the dimensions of the original and masked image)\n",
        "\n"
      ],
      "metadata": {
        "id": "5BhVvHIxo7KL"
      },
      "id": "5BhVvHIxo7KL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the average timecourse within the brain aka the global signal timecourse (hint use the output from the previous step and basic python tools for working with arrays that you learned in previous lectures)\n",
        "\n",
        "# plot the global signal timecourse with time on the x-axis (remember that you dropped the first 10 timepoints!)\n"
      ],
      "metadata": {
        "id": "mZbhTr3_rKoL"
      },
      "id": "mZbhTr3_rKoL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ADVANCED ###\n",
        "# plot the carpet plot by checking the arguments of nilearn's plot_carpet function on your own and plot also the global signal timecourse above it such that the x-axes are aligned\n",
        "# hint: the carpet plot function has an axes argument\n",
        "fig, ax = plt.subplots()\n",
        "ax[0].plot()\n",
        "plotting.plot_carpet()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bn37P0lSpfdM"
      },
      "id": "Bn37P0lSpfdM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3.4"
      ],
      "metadata": {
        "id": "Vef0vtmRZptP"
      },
      "id": "Vef0vtmRZptP"
    },
    {
      "cell_type": "code",
      "source": [
        "# clean your image to : standardize, filter between 0.01 and 0.1Hz and regress the global signal.\n",
        "# the TR of this dataset is 1.2s\n",
        "clean_img ="
      ],
      "metadata": {
        "id": "toHxCyRvZv7d"
      },
      "id": "toHxCyRvZv7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the global timeseries of the resulting clean_img as well as the file that I provided called bold_img_clean (this was cleaned with motion and WM/CSF regression)\n"
      ],
      "metadata": {
        "id": "G_jPqZnuag5v"
      },
      "id": "G_jPqZnuag5v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a single timepoint from the two images using plot stat_map (the one you regressed global signal from and the provided cleaned image)\n"
      ],
      "metadata": {
        "id": "m_YZNp_ocIsJ"
      },
      "id": "m_YZNp_ocIsJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##$ ADVANCED ###\n",
        "\n",
        "# perform ICA with 5 components. Do this 3 times - on the raw data, on the data that you cleaned with global signal regression, and on the cleaned provided data"
      ],
      "metadata": {
        "id": "K7zsUWg-blCD"
      },
      "id": "K7zsUWg-blCD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import CanICA module\n",
        "from nilearn.decomposition import CanICA\n",
        "\n",
        "# Specify relevant parameters\n",
        "n_components = 5\n",
        "fwhm = 0.3\n",
        "\n",
        "# Specify CanICA object\n",
        "canica = CanICA(mask = bold_mask, #only compute components within the brain\n",
        "                n_components=n_components, #the number of ICA components to derive - check the literature for relevant values\n",
        "                smoothing_fwhm=fwhm, #size of smoothing kernel in mm\n",
        "                memory=\"nilearn_cache\", memory_level=2,\n",
        "                threshold='auto', verbose=10, random_state=0, n_jobs=-1,\n",
        "                standardize=True)"
      ],
      "metadata": {
        "id": "xjLwNGtcbzxw"
      },
      "id": "xjLwNGtcbzxw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run/fit CanICA on input data\n",
        "\n",
        "\n",
        "# Retrieve the independent components in brain space\n",
        "\n",
        "#plot"
      ],
      "metadata": {
        "id": "tz55VMFLeYxM"
      },
      "id": "tz55VMFLeYxM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7UypaIDfLa1"
      },
      "id": "o7UypaIDfLa1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}