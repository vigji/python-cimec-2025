{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a44e75",
   "metadata": {},
   "source": [
    "# Practicals for lecture 1.0\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec-2025/blob/main/practicals/Practicals_1.0.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a4f38",
   "metadata": {},
   "source": [
    "## Introduction to `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d801e0",
   "metadata": {},
   "source": [
    "#### 1.0.0 Creating numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be7ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d604249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, 5, 6, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a numpy array from this list:\n",
    "\n",
    "my_list = [3,2,4,5,6,1]\n",
    "\n",
    "np.array(my_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ff392e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What shape do you expect to see in the array that come from converting\n",
    "# to numpy this list of lists of lists? Make your prediction, then convert list to array \n",
    "# and check the result!\n",
    "my_list_of_lists = [[[1, 2, 3, 4], [5,6,7,8], [9,10,11,12]], \n",
    "                    [[13,14,15,16], [17,18,19,20], [21,22,23,24]]]\n",
    "\n",
    "many_lists_arr = np.array(my_list_of_lists)\n",
    "many_lists_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2943acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(3, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a 3D numpy array full of zeros of shape (3, 2, 10). \n",
    "# Check its  `ndim` and `shape` attributes to make sure it is correct!\n",
    "\n",
    "my_array = np.zeros((3, 2, 10))\n",
    "print(my_array.ndim)\n",
    "print(my_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e68980b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 204)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a numpy array full of ones of shape (3, 2, 10). Make it of data type np.uint16!\n",
    "# Bonus: check its size in memory and compare it with the size of the zeros array we defined above!\n",
    "# You can use the sys.getsizeof() function to check the size in memory of the array.\n",
    "\n",
    "my_array_uint16 = np.zeros((3, 2, 10), dtype=np.uint8)\n",
    "my_array_uint16.dtype\n",
    "\n",
    "sys.getsizeof(my_array), sys.getsizeof(my_array_uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "097ed893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an array of shape (3, 2, 10) full of nans:\n",
    "\n",
    "my_array = np.full( (3, 2, 10), np.nan)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "261247fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32,\n",
       "       34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66,\n",
       "       68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a 1D array containing all even numbers from 0 to 100:\n",
    "my_array = np.arange(0, 100, 2)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6737560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google (or ask chatGPT) how to use np.random to generate normally distributed values. \n",
    "# Then, create an array of normally distributed values and shape (4,5,2) called random_matrix.\n",
    "\n",
    "random_array = np.random.normal(0, 1, (4,5,2))\n",
    "random_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9a08933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 3, 2, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Advanced]: \n",
    "# 1) Another useful np.random function is shuffle, to change the order of elements in a list/array. \n",
    "# try it out! Does it return a new array or does it work inplace?\n",
    "arr_to_shuffle = np.arange(5)\n",
    "np.random.shuffle(arr_to_shuffle)\n",
    "\n",
    "arr_to_shuffle  # this works inplace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) try initializing random arrays of different dtypes and look at their size in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc43a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) From the exercise above, you can imagine that sometimes using u/int8 or u/int16 can spare a lot of space\n",
    "# when working with arrays. However, those types can only store integers. \n",
    "# Can you imagine what you could do to convert float values in the range 0-1 to integers that you can store\n",
    "# using uint8 or uint16? \n",
    "# write a function that takes as input an array of floats between 0 and 1 and convert it in uint16 format \n",
    "# maintaning as much information as possible. Write also a function to transform the array back to the original float form.\n",
    "to_be_compressed = np.random.rand(1000, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366e16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Can you estimate what is the resolution limit of the uint8 and uint16 encoded arrays? Resolution \n",
    "# could be defined as the minimum difference between two numbers that will make them mapped as different values\n",
    "# in the uint8 or uint16 encoded arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77402a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Given a dtype - let's say float - try to figure out how much memory is required to store each number of the array, \n",
    "# and how much memory is allocated as an overhead just to initialize the array.\n",
    "# You can do this by creating arrays of different sizes (you can keep it 1D for simplicity) in a loop,\n",
    "# creating a list or an array with the array sized you measure with sys.getsizeof() and then plot this curve\n",
    "# using matplotlib plt.plot() (I assume you can do this if you're reading this)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a5116",
   "metadata": {},
   "source": [
    "#### 1.0.1 Indexing and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57b9def5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337]\n",
      " [-0.23413696  1.57921282  0.76743473 -0.46947439  0.54256004]\n",
      " [-0.46341769 -0.46572975  0.24196227 -1.91328024 -1.72491783]\n",
      " [-0.56228753 -1.01283112  0.31424733 -0.90802408 -1.4123037 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-0.13826430117118466)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You are given this 2D array:\n",
    "np.random.seed(42)\n",
    "random_array = np.random.normal(0, 1, (4, 5))\n",
    "\n",
    "# use numpy indexing to address the element (0, 1) (first row, second column) from random_array:\n",
    "print(random_array)\n",
    "\n",
    "random_array[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63bb4bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.23413696,  1.57921282,  0.76743473, -0.46947439,  0.54256004])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use numpy indexing to select all values in the second row from random_matrix above:\n",
    "\n",
    "random_array[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9da177f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49671415 -0.1382643 ]\n",
      " [ 0.64768854  1.52302986]\n",
      " [-0.23415337 -0.23413696]]\n",
      "[[False  True]\n",
      " [False False]\n",
      " [ True  True]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49671415,        nan],\n",
       "       [0.64768854, 1.52302986],\n",
       "       [       nan,        nan]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set to replace with np.nan all the negative values in the matrix below:\n",
    "np.random.seed(42)\n",
    "random_matrix = np.random.normal(0, 1, (3,2))\n",
    "print(random_matrix)\n",
    "\n",
    "selector = random_matrix < 0\n",
    "print(selector)\n",
    "\n",
    "random_matrix[selector] = np.nan\n",
    "\n",
    "random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7787f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">get_dataset_dir</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/Users/vigji/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">development_fmri</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mget_dataset_dir\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/Users/vigji/nilearn_data/\u001b[0m\u001b[95mdevelopment_fmri\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">get_dataset_dir</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/Users/vigji/nilearn_data/development_fmri/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">development_fmri</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mget_dataset_dir\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/Users/vigji/nilearn_data/development_fmri/\u001b[0m\u001b[95mdevelopment_fmri\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">get_dataset_dir</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/Users/vigji/nilearn_data/development_fmri/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">development_fmri</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mget_dataset_dir\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/Users/vigji/nilearn_data/development_fmri/\u001b[0m\u001b[95mdevelopment_fmri\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fMRI data\n",
    "\n",
    "# The code snippet below loads a single fmri scan into an array (fmri_array).\n",
    "# This scan consists of 50x59 voxels in each slice, 50 axial slices, 168 timepoints.\n",
    "\n",
    "# First, run this cell to load the data:\n",
    "# !pip install nilearn\n",
    "from nilearn import datasets, image, plotting\n",
    "data = datasets.fetch_development_fmri(n_subjects=1)\n",
    "fmri_img = image.load_img(data.func[0])\n",
    "fmri_array = image.get_data(fmri_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f529f955",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fmri_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print out the shape of the array to check the dimensions, and find the time axis (remember, we have 168 timepoints).\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfmri_array\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Select the volume correponding to the 100th timepoint, then print the shape of the volume to check the dimensions\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# and if they make sense to you given the specs of the scan given above:\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fmri_array' is not defined"
     ]
    }
   ],
   "source": [
    "# Print out the shape of the array to check the dimensions, and find the time axis (remember, we have 168 timepoints).\n",
    "fmri_array.shape\n",
    "\n",
    "# Select the volume correponding to the 100th timepoint, then print the shape of the volume to check the dimensions\n",
    "# and if they make sense to you given the specs of the scan given above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df040051",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ed148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now slice the volume on the 3rd axis to get the 20th slice, and plot it using plt.imshow:\n",
    "# Bonus: check the documentation of plt.imshow and play with the vmin and vmax arguments to control the contrast range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets say that you know that timepoints 30-40 and 99-114 are corrupted by high levels of motion, \n",
    "# so you want to remove them (an approach known as motion censoring).\n",
    "# Create a boolean array that indicates which timepoints need to be censored - a censoring timeseries essentially. \n",
    "# (Hint: you can do this by creating a boolean array of zeros and use slicing to set the correct values to 1)\n",
    "# \n",
    "# The number of timepoints in your array should be match the number of timepoints in your scan.\n",
    "\n",
    "\n",
    "# Now apply the censoring timeseries to your scan to remove the corrupted timepoints. \n",
    "# Check that the number of remaining timepoints is as you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images are just arrays! This is one of the reasons working with arrays is so important!\n",
    "# (Usually images are H x W x 3 arrays, with the third dimension storing the values\n",
    "# for each of the RGB channels. Here the image will be grayscale, so we only have 2D - no colors!).\n",
    "\n",
    "# Use the function below to download an image, and print the shape of the array to know the number of pixels. \n",
    "# Then, use plt.matshow to visualize it.\n",
    "\n",
    "def fetch_image():\n",
    "    \"\"\"Fetch exercise data from github repo. \n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray\n",
    "            Array with the exercise data.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # You should never import stuff in a function! I'm doing it here\n",
    "    # just to keep together all the code that you don't really need to read now.\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "\n",
    "    # URL of the .npy file on GitHub:\n",
    "    URL = \"https://github.com/vigji/python-cimec/raw/main/practicals/data/corrupted_img.npy\"\n",
    "\n",
    "    response = requests.get(URL)\n",
    "    \n",
    "    return np.load(BytesIO(response.content))\n",
    "\n",
    "\n",
    "# Tip 1: remember to import matplotlib.pyplot first - and give it an alias! (\"import ... as ...\")\n",
    "# Tip 2: to make the image grayscale, you can pass the cmap=\"gray\" argument to the matshow() function!\n",
    "\n",
    "img = fetch_image()  #Â print its shape to know the number of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like the image got corrupted with some noise! \n",
    "# To understand the noise pattern, you can try to look closer to it.\n",
    "# Zoom in the image: plot it again, but selecting a small region using indexing \n",
    "# (e.g., img[10:80, 70:130])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc78853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you understand what is going on? Can you think of an indexing strategy \n",
    "# that would filter out the noise?\n",
    "# Try to retrieve the uncorrupted image with an indexing operation, and plot it!\n",
    "\n",
    "# (See cell below if you are really stuck!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ee116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: it looks like one every two columns of pixels has weird values! You could try to keep only one column every two..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dddce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Advanced]\n",
    "# 1) check the type of the image array. Then, check its maximum. Is this data represented efficiently?\n",
    "#   If not, convert it to the format that would preserve information with the maximum memory efficiency\n",
    "\n",
    "# 2) As we mentioned, color images are just (w, h, 3) arrays where the third dimension correspond to color.\n",
    "# Color is represented by triplets of numbers indicating the load over the Red, the Blue, and the Green axis.\n",
    "# Let's make a colored version of the image, where the left side of the image appears red, the center blue,\n",
    "# and the right green!\n",
    "# To do so, initialize an empty (w,h,3) array and use indexing to fill with the image values the correct\n",
    "# channels in different parts of the image. Bonus points: do it with a loop.\n",
    "# After you have done it, consider this question: were you working inplace or on copies?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-env",
   "language": "python",
   "name": "lab-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
